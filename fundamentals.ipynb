{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [

      "c:\\Users\\Mallinathan G\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.12.1+cu116'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors\n",
    "\n",
    "Tensors are similar to lists/arrays but are often seen in multiple dimensions (greater than 3)\n",
    "The biggest plus of tensors is data manipulation in bulk that has been optimised for efficiency like  running in GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining a scalar (unit or 0 dim tensor)\n",
    "scalar = torch.tensor(5)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check the tensor dimension\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get the value of the scalar\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 77, 774])\n",
      "1\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "#similar to vectors\n",
    "vect = torch.tensor([77, 774])\n",
    "print(vect)\n",
    "print(vect.ndim)\n",
    "print(vect.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 2, 3],\n",
      "          [3, 6, 9],\n",
      "          [2, 4, 5]],\n",
      "\n",
      "         [[1, 2, 3],\n",
      "          [3, 6, 9],\n",
      "          [2, 4, 5]],\n",
      "\n",
      "         [[1, 2, 3],\n",
      "          [3, 6, 9],\n",
      "          [2, 4, 5]]]])\n",
      "4\n",
      "torch.Size([1, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "#more complex\n",
    "# Tensor\n",
    "TENSOR = torch.tensor([[[[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]],\n",
    "                        [[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]], \n",
    "                        [[1, 2, 3],\n",
    "                        [3, 6, 9],\n",
    "                        [2, 4, 5]]]])\n",
    "print(TENSOR)\n",
    "print(TENSOR.ndim)\n",
    "print(TENSOR.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5102, 0.5137, 0.3225]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "random_Tensor = torch.rand(size=(1,3))\n",
    "print(random_Tensor)\n",
    "print(random_Tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#Init with zeros or ones\n",
    "zeros = torch.zeros(size = (3,4))\n",
    "print(zeros)\n",
    "ones = torch.ones(size = (3, 4))\n",
    "print(ones)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating tenosr range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18])\n"
     ]
    }
   ],
   "source": [
    "a_range_Tensor = torch.arange(start=0, end=20, step=2)\n",
    "print(a_range_Tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a tensor A of shape tensor random_Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "Tensor_A = torch.zeros_like(input=random_Tensor)\n",
    "print(Tensor_A)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATATYPES\n",
    "Torch.tensor have data types which can be classified into 3 main catagories\n",
    "\n",
    "dtype=None (default-torch.float32, others include, torch.(float16 (half), float8)) -> For precision \n",
    "\n",
    "device=None (default cpu else torch.cuda)\n",
    "\n",
    "requires_grad = False (/True) a feature to efficiently and automatically compute gradients during back prop\n",
    "\n",
    "Please note that, when performing manipulations of 2 tensors, make sure dtype and device are same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3.,  5., 54.], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "Tensor_cuda_16 = torch.tensor([3, 5, 54], dtype=torch.float16, device=\"cuda\", requires_grad=False)\n",
    "print(Tensor_cuda_16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To yield the attributes of a tensor (the one mentioned above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor is tensor([[0.6693, 0.6998, 0.3987, 0.5417],\n",
      "        [0.9219, 0.9644, 0.0999, 0.6125],\n",
      "        [0.9594, 0.7954, 0.6628, 0.9068],\n",
      "        [0.2373, 0.9488, 0.7798, 0.5734],\n",
      "        [0.0129, 0.6953, 0.0325, 0.5756]])\n",
      "The type is:  torch.float32\n",
      "The shape is  torch.Size([5, 4])\n",
      "The decice is  cpu\n"
     ]
    }
   ],
   "source": [
    "#creating a random tensor\n",
    "Tensor_rand = torch.rand(5,4)\n",
    "print(\"The tensor is\", Tensor_rand)\n",
    "print(\"The type is: \", Tensor_rand.dtype)\n",
    "print(\"The shape is \", Tensor_rand.shape)\n",
    "print(\"The decice is \", Tensor_rand.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([50, 60])\n",
      "tensor([ 80, 100])\n",
      "tensor([30, 40])\n",
      "tensor([400, 500])\n",
      "tensor([4., 5.])\n",
      "tensor([400, 500])\n"
     ]
    }
   ],
   "source": [
    "#create\n",
    "sample_Tensor = torch.tensor([40, 50])\n",
    "print(sample_Tensor+10)\n",
    "print(sample_Tensor*2)\n",
    "print(sample_Tensor-10)\n",
    "print(torch.multiply(sample_Tensor, 10))\n",
    "print(sample_Tensor/10)\n",
    "sample_Tensor = sample_Tensor * 10\n",
    "print(sample_Tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix Multiplication\n",
    "\n",
    "provided by torch.matmul() which is faster than manual (using loops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3, 22],\n",
      "        [ 1, 21]])\n",
      "tensor([[ 31, 528],\n",
      "        [ 24, 463]])\n",
      "tensor([[ 31, 528],\n",
      "        [ 24, 463]])\n",
      "tensor([[ 31, 528],\n",
      "        [ 24, 463]])\n",
      "Transpose =  tensor([[ 3,  1],\n",
      "        [22, 21]])\n"
     ]
    }
   ],
   "source": [
    "sample_Tensor = torch.randint(low=0, high=30, size=(2,2))\n",
    "print(sample_Tensor)\n",
    "print(torch.matmul(sample_Tensor, sample_Tensor))\n",
    "#In short\n",
    "print(torch.mm(sample_Tensor, sample_Tensor))\n",
    "# a depreciated method for the same\n",
    "print(sample_Tensor @ sample_Tensor)\n",
    "#Transpose\n",
    "print(\"Transpose = \", sample_Tensor.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample torch neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.]]) torch.Size([1, 3])\n",
      "tensor([[ 0.5214, -0.4904,  0.4457,  0.0961, -0.1875,  0.3568,  0.0900,  0.4665,\n",
      "          0.0631, -0.1821]], grad_fn=<AddmmBackward0>) torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "#setting random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "linear = torch.nn.Linear(in_features=3, out_features=10)\n",
    "x = Tensor_A\n",
    "y = linear(x)\n",
    "print(x, x.shape)\n",
    "print(y, y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[23, 17, 11,  9],\n",
      "        [18, 14, 27,  5],\n",
      "        [25, 11, 30, 31],\n",
      "        [34, 25,  5,  8]])\n",
      "tensor(34) tensor(12)\n",
      "tensor(5) tensor(7)\n",
      "tensor(293)\n",
      "tensor(18.3125, dtype=torch.float16)\n",
      "tensor(18.3125, dtype=torch.float64) torch.float64\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2)\n",
    "#creating\n",
    "sample_Tensor = torch.randint(low=0, high=35, size=(4,4))\n",
    "print(sample_Tensor)\n",
    "print(torch.max(sample_Tensor), torch.argmax(sample_Tensor))\n",
    "print(torch.min(sample_Tensor), torch.argmin(sample_Tensor))\n",
    "print(torch.sum(sample_Tensor))\n",
    "mean = torch.mean(sample_Tensor.type(torch.half))\n",
    "print(mean)\n",
    "#To change mean from half (float16) to 64\n",
    "mean = mean.type(torch.float64)\n",
    "print(mean, mean.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor shape manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7])\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7]])\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7]]) tensor([1, 2, 3, 4, 5, 6, 7])\n",
      "tensor([[23,  2,  3,  4,  5,  6,  7]]) tensor([23,  2,  3,  4,  5,  6,  7])\n",
      "tensor([[23,  2,  3,  4,  5,  6,  7],\n",
      "        [23,  2,  3,  4,  5,  6,  7],\n",
      "        [23,  2,  3,  4,  5,  6,  7],\n",
      "        [23,  2,  3,  4,  5,  6,  7],\n",
      "        [23,  2,  3,  4,  5,  6,  7]])\n",
      "tensor([[23, 23, 23, 23, 23],\n",
      "        [ 2,  2,  2,  2,  2],\n",
      "        [ 3,  3,  3,  3,  3],\n",
      "        [ 4,  4,  4,  4,  4],\n",
      "        [ 5,  5,  5,  5,  5],\n",
      "        [ 6,  6,  6,  6,  6],\n",
      "        [ 7,  7,  7,  7,  7]])\n",
      "tensor([23,  2,  3,  4,  5,  6,  7])\n",
      "tensor([[23],\n",
      "        [ 2],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 6],\n",
      "        [ 7]])\n",
      "tensor([[23,  2,  3,  4,  5,  6,  7]])\n",
      "torch.Size([24, 124, 224, 3])\n",
      "torch.Size([3, 224, 24, 124])\n"
     ]
    }
   ],
   "source": [
    "#creating\n",
    "a = torch.arange(1,8)\n",
    "print(a)\n",
    "b = a.reshape(1, 7)\n",
    "print(b)\n",
    "c = a.view(1, 7)\n",
    "print(c, a)\n",
    "#view is like call by reference and altering c would alter a\n",
    "c[:,0] = 23\n",
    "print(c, a)\n",
    "#stacking a 5 times to x\n",
    "x = torch.stack([a, a, a, a, a], dim=0)\n",
    "print(x)\n",
    "x1 = torch.stack([a, a, a, a, a], dim=1)\n",
    "print(x1)\n",
    "#squeeze would remove all single dimensions \n",
    "print(c.squeeze())\n",
    "#unsqueeze would do the opposite\n",
    "print(a.unsqueeze(dim=1))\n",
    "print(a.unsqueeze(dim=0))\n",
    "#permute helps to change the dimensions the way i want\n",
    "#note that permute returns a view and be careful with item manipulation\n",
    "a = torch.rand(24, 124, 224, 3)\n",
    "print(a.shape)\n",
    "b = a.permute(3, 2, 0, 1)\n",
    "print(b.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing is the same as list or numpy indexing\n",
    "Numpy and pytorch\n",
    "2 commands to convert between tensor and numpy\n",
    "\n",
    "torch.from_numpy(numpy_array) -> numpy to tensor\n",
    "Numpy works in float 64 by default and hence it will be float 64 unless typecasted\n",
    "\n",
    "torch.tensor_variable.numpy() ->opposite\n",
    "defaulting to float 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64)\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numpy_arr = np.arange(1.0, 10.0)\n",
    "print(numpy_arr)\n",
    "tensor_numpy = torch.from_numpy(numpy_arr)\n",
    "print(tensor_numpy)\n",
    "tensor = torch.arange(0, 10)\n",
    "print(tensor)\n",
    "numpy_tensor = tensor.numpy()\n",
    "print(numpy_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducibility\n",
    "Use random seed for the same\n",
    "Make sure to set seed everytime during assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A =  tensor([[0.5007, 0.2445, 0.5864, 0.4192],\n",
      "        [0.0114, 0.3972, 0.0118, 0.8016],\n",
      "        [0.4381, 0.0169, 0.9721, 0.3844]])\n",
      "B =  tensor([[0.8651, 0.7167, 0.7172, 0.3774],\n",
      "        [0.4032, 0.1604, 0.4416, 0.2682],\n",
      "        [0.7461, 0.0613, 0.6997, 0.7458]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n",
      "C =  tensor([[0.7576, 0.2793, 0.4031, 0.7347],\n",
      "        [0.0293, 0.7999, 0.3971, 0.7544],\n",
      "        [0.5695, 0.4388, 0.6387, 0.5247]])\n",
      "D =  tensor([[0.7576, 0.2793, 0.4031, 0.7347],\n",
      "        [0.0293, 0.7999, 0.3971, 0.7544],\n",
      "        [0.5695, 0.4388, 0.6387, 0.5247]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#non reprodicible\n",
    "tensor_A = torch.rand(3,4)\n",
    "tensor_B = torch.rand(3,4)\n",
    "print(\"A = \", tensor_A)\n",
    "print(\"B = \", tensor_B)\n",
    "print(tensor_A==tensor_B)\n",
    "\n",
    "#with manual seed\n",
    "torch.random.manual_seed(1)\n",
    "tensor_C = torch.rand(3, 4)\n",
    "torch.random.manual_seed(1)\n",
    "tensor_D = torch.rand(3, 4)\n",
    "print(\"C = \", tensor_C)\n",
    "print(\"D = \", tensor_D)\n",
    "print(tensor_C==tensor_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 19 17:18:57 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.98                 Driver Version: 535.98       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce MX150         WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   49C    P0              N/A / ERR! |    340MiB /  2048MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     18344      C   ...rograms\\Python\\Python310\\python.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#to get Nvidia info\n",
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch can work with GPUs better and has options to work on multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#assign gpu as device if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "#to know the number of GPUs available\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) cpu\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "source": [
    "#running on CPU\n",
    "sample_Tensor = torch.arange(10)\n",
    "print(sample_Tensor, sample_Tensor.device)\n",
    "\n",
    "#shifting it to gpu\n",
    "sample_Tensor_gpu = sample_Tensor.to(device)\n",
    "print(sample_Tensor_gpu, sample_Tensor_gpu.device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the cude:0 means that, the tenosr is stored in the 0th GPU and can be varied based on number of GPUs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also know that numpy conversion wont work with GPU variables and hence need to be converted back \n",
    "\n",
    "sample_Tensor_gpu.numpy()\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "TypeError                                 Traceback (most recent call last)\n",
    "d:\\padipu\\ML\\pytorch_Course\\fundamentals.ipynb Cell 39 in ()\n",
    "----> 1 sample_Tensor_gpu.numpy()\n",
    "\n",
    "TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
    "\n",
    "Hence,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_tensor = sample_Tensor_gpu.cpu().numpy()\n",
    "numpy_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
